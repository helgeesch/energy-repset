{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 6: Constructive Algorithms\n",
    "\n",
    "Examples 1--5 all use the **Generate-and-Test** workflow: enumerate candidates, score each one, pick the best. Constructive algorithms work differently — they **build** solutions iteratively using their own internal objectives.\n",
    "\n",
    "This notebook demonstrates three constructive algorithms:\n",
    "\n",
    "| Algorithm | Idea | Internal objective | Output |\n",
    "|-----------|------|-------------------|--------|\n",
    "| **Hull Clustering** | Select periods that span the convex hull of the feature space | Minimize projection error | Subset + blended weights |\n",
    "| **CTPC** | Hierarchical clustering that only merges *temporally adjacent* periods | Minimize within-cluster sum of squares | Contiguous segments + segment-size weights |\n",
    "| **Snippet** | Greedy selection of multi-day subsequences via p-median | Minimize total distance to nearest snippet | Subsequence starts + assignment-fraction weights |\n",
    "\n",
    "Because these algorithms have their own built-in objectives, they do not use the `ObjectiveSet` during search — only for optional post-hoc evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import energy_repset as rep\n",
    "import energy_repset.diagnostics as diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://tubcloud.tu-berlin.de/s/pKttFadrbTKSJKF/download/time-series-lecture-2.csv\"\n",
    "df_raw = pd.read_csv(url, index_col=0, parse_dates=True).rename_axis('variable', axis=1)\n",
    "df_raw = df_raw.drop('prices', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Hull Clustering\n",
    "\n",
    "Hull Clustering selects periods that form the vertices of a convex hull enclosing the data in feature space. The intuition: if your representatives span the \"boundary\" of the data cloud, every other period can be expressed as a convex combination of them — which is exactly what the blended representation model does.\n",
    "\n",
    "The algorithm greedily adds the period that most reduces the total projection error (i.e., the error from approximating all periods as convex combinations of the selected ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_monthly = rep.ProblemContext(df_raw=df_raw, slicer=rep.TimeSlicer(unit=\"month\"))\n",
    "\n",
    "workflow_hull = rep.Workflow(\n",
    "    feature_engineer=rep.StandardStatsFeatureEngineer(),\n",
    "    search_algorithm=rep.HullClusteringSearch(k=3, hull_type='convex'),\n",
    "    representation_model=rep.BlendedRepresentationModel(blend_type='convex'),\n",
    ")\n",
    "experiment_hull = rep.RepSetExperiment(context_monthly, workflow_hull)\n",
    "result_hull = experiment_hull.run()\n",
    "\n",
    "print(f\"Selection:        {result_hull.selection}\")\n",
    "print(f\"Projection error: {result_hull.scores['projection_error']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate blended weights for bar chart\n",
    "if isinstance(result_hull.weights, pd.DataFrame):\n",
    "    agg = result_hull.weights.sum(axis=0)\n",
    "    weights_hull_agg = (agg / agg.sum()).to_dict()\n",
    "else:\n",
    "    weights_hull_agg = result_hull.weights\n",
    "\n",
    "fig = diag.ResponsibilityBars().plot(weights_hull_agg, show_uniform_reference=True)\n",
    "fig.update_layout(title='Hull Clustering: Responsibility Weights (Blended, Aggregated)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ctx_hull = experiment_hull.feature_context\n",
    "cols = list(feature_ctx_hull.df_features.columns[:2])\n",
    "\n",
    "fig = diag.FeatureSpaceScatter2D().plot(\n",
    "    feature_ctx_hull.df_features, x=cols[0], y=cols[1], selection=result_hull.selection\n",
    ")\n",
    "fig.update_layout(title='Hull Clustering: Feature Space')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slicer_monthly = rep.TimeSlicer(unit=\"month\")\n",
    "selected_idx = slicer_monthly.get_indices_for_slice_combi(df_raw.index, result_hull.selection)\n",
    "df_sel = df_raw.loc[selected_idx]\n",
    "\n",
    "fig = diag.DistributionOverlayECDF().plot(df_raw['load'], df_sel['load'])\n",
    "fig.update_layout(title='Hull Clustering: ECDF Overlay (Load)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. CTPC (Chronological Time-Period Clustering)\n",
    "\n",
    "CTPC is hierarchical agglomerative clustering with a **contiguity constraint**: only temporally adjacent periods can be merged. This guarantees the output is a set of contiguous segments — e.g., \"Jan-Mar\", \"Apr-Jun\", etc. — which is useful for models with long-duration storage or seasonal dynamics.\n",
    "\n",
    "Weights reflect the size of each segment relative to the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow_ctpc = rep.Workflow(\n",
    "    feature_engineer=rep.StandardStatsFeatureEngineer(),\n",
    "    search_algorithm=rep.CTPCSearch(k=4, linkage='ward'),\n",
    "    representation_model=rep.UniformRepresentationModel(),\n",
    ")\n",
    "experiment_ctpc = rep.RepSetExperiment(context_monthly, workflow_ctpc)\n",
    "result_ctpc = experiment_ctpc.run()\n",
    "\n",
    "print(f\"Selection: {result_ctpc.selection}\")\n",
    "print(f\"WCSS:      {result_ctpc.scores['wcss']:.4f}\")\n",
    "print(f\"Weights:   { {str(k): round(v, 3) for k, v in result_ctpc.weights.items()} }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'segments' in result_ctpc.diagnostics:\n",
    "    print(\"Contiguous segments:\")\n",
    "    for seg in result_ctpc.diagnostics['segments']:\n",
    "        print(f\"  {seg['start']} -- {seg['end']}  \"\n",
    "              f\"(size={seg['size']}, representative={seg['representative']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = diag.ResponsibilityBars().plot(result_ctpc.weights, show_uniform_reference=True)\n",
    "fig.update_layout(title='CTPC: Responsibility Weights (Segment Fractions)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ctx_ctpc = experiment_ctpc.feature_context\n",
    "cols = list(feature_ctx_ctpc.df_features.columns[:2])\n",
    "\n",
    "fig = diag.FeatureSpaceScatter2D().plot(\n",
    "    feature_ctx_ctpc.df_features, x=cols[0], y=cols[1], selection=result_ctpc.selection\n",
    ")\n",
    "fig.update_layout(title='CTPC: Feature Space')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_idx_ctpc = slicer_monthly.get_indices_for_slice_combi(df_raw.index, result_ctpc.selection)\n",
    "df_sel_ctpc = df_raw.loc[selected_idx_ctpc]\n",
    "\n",
    "fig = diag.DistributionOverlayECDF().plot(df_raw['load'], df_sel_ctpc['load'])\n",
    "fig.update_layout(title='CTPC: ECDF Overlay (Load)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Snippet Algorithm\n",
    "\n",
    "The Snippet algorithm is designed for **multi-day representative periods** (e.g., weeks). Instead of comparing entire weeks as monolithic objects, it compares day-level \"snippets\" within candidate periods. This avoids the problem where a single anomalous day makes an entire week look unique.\n",
    "\n",
    "It uses a greedy p-median approach: iteratively select the snippet whose addition most reduces the total distance from all days to their nearest selected snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_daily = rep.ProblemContext(df_raw=df_raw, slicer=rep.TimeSlicer(unit=\"day\"))\n",
    "\n",
    "workflow_snippet = rep.Workflow(\n",
    "    feature_engineer=rep.DirectProfileFeatureEngineer(),\n",
    "    search_algorithm=rep.SnippetSearch(k=4, period_length_days=7, step_days=7),\n",
    "    representation_model=rep.UniformRepresentationModel(),\n",
    ")\n",
    "experiment_snippet = rep.RepSetExperiment(context_daily, workflow_snippet)\n",
    "result_snippet = experiment_snippet.run()\n",
    "\n",
    "print(f\"Selection (start days): {result_snippet.selection}\")\n",
    "print(f\"Total distance:         {result_snippet.scores['total_distance']:.4f}\")\n",
    "print(f\"Weights:                { {str(k): round(v, 3) for k, v in result_snippet.weights.items()} }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = diag.ResponsibilityBars().plot(result_snippet.weights, show_uniform_reference=True)\n",
    "fig.update_layout(title='Snippet: Responsibility Weights (Assignment Fractions)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slicer_daily = rep.TimeSlicer(unit=\"day\")\n",
    "selected_idx_snippet = slicer_daily.get_indices_for_slice_combi(\n",
    "    df_raw.index, result_snippet.selection\n",
    ")\n",
    "df_sel_snippet = df_raw.loc[selected_idx_snippet]\n",
    "\n",
    "fig = diag.DistributionOverlayECDF().plot(df_raw['load'], df_sel_snippet['load'])\n",
    "fig.update_layout(title='Snippet: ECDF Overlay (Load)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "All three constructive algorithms find solutions without evaluating an external objective set. Their internal objectives are tightly coupled to the algorithm mechanics, which makes them fast but less modular than Generate-and-Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Algorithm':<25} {'k':>3} {'Internal Score':>20} {'Value':>10}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Hull Clustering':<25} {'3':>3} {'projection_error':>20} \"\n",
    "      f\"{result_hull.scores['projection_error']:>10.4f}\")\n",
    "print(f\"{'CTPC':<25} {'4':>3} {'wcss':>20} \"\n",
    "      f\"{result_ctpc.scores['wcss']:>10.4f}\")\n",
    "print(f\"{'Snippet':<25} {'4':>3} {'total_distance':>20} \"\n",
    "      f\"{result_snippet.scores['total_distance']:>10.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}